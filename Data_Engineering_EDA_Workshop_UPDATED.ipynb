{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b28fa9b",
   "metadata": {},
   "source": [
    "# Data Engineering & EDA Workshop\n",
    "\n",
    "This notebook demonstrates cloud database connection, data engineering, EDA, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b120cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary faker sqlalchemy scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fdba7e",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "We use a Neon PostgreSQL database and synthetic data generated with Faker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e668c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NEON_DB_URL = \"postgresql://neondb_owner:npg_oVLxIZk49eiX@ep-dark-base-aiac0jg1-pooler.c-4.us-east-1.aws.neon.tech/neondb?sslmode=require&channel_binding=require\"\n",
    "conn = psycopg2.connect(NEON_DB_URL)\n",
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0e416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS employees (\n",
    "    employee_id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(100),\n",
    "    position VARCHAR(50),\n",
    "    start_date DATE,\n",
    "    salary INTEGER\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba44024",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fake = Faker()\n",
    "positions = [\n",
    "    \"Software Engineer\", \"Data Scientist\", \"DevOps Engineer\",\n",
    "    \"Cloud Architect\", \"Cybersecurity Analyst\", \"AI Engineer\", \"Backend Developer\"\n",
    "]\n",
    "\n",
    "employees = []\n",
    "for _ in range(50):\n",
    "    employees.append((\n",
    "        fake.name(),\n",
    "        random.choice(positions),\n",
    "        fake.date_between(start_date='-9y', end_date='today'),\n",
    "        random.randint(60000, 200000)\n",
    "    ))\n",
    "\n",
    "cur.executemany(\"\"\"\n",
    "INSERT INTO employees (name, position, start_date, salary)\n",
    "VALUES (%s, %s, %s, %s);\n",
    "\"\"\", employees)\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18ef7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_sql(\"SELECT * FROM employees;\", conn)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec6267",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning\n",
    "Checking structure and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79130ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.info()\n",
    "df.isnull().sum()\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf50947",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "Extracting start year and years of service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4be3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['start_year'] = pd.to_datetime(df['start_date']).dt.year\n",
    "df['years_of_service'] = 2025 - df['start_year']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9af470",
   "metadata": {},
   "source": [
    "## 4. Scaling\n",
    "Applying StandardScaler to salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c808a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df['salary_scaled'] = scaler.fit_transform(df[['salary']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803bab69",
   "metadata": {},
   "source": [
    "## 5. Visualization 1\n",
    "Average Salary by Position and Start Year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c0c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "grouped = df.groupby(['position', 'start_year'])['salary'].mean().unstack()\n",
    "grouped.plot(kind='bar', figsize=(14,6))\n",
    "plt.title(\"Average Salary by Position and Start Year\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04614ca4",
   "metadata": {},
   "source": [
    "## 6. Advanced Visualization\n",
    "Creating departments and joining tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098c4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS departments (\n",
    "    department_id SERIAL PRIMARY KEY,\n",
    "    department_name VARCHAR(50),\n",
    "    location VARCHAR(50)\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e593b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Populate departments: 50 clean rows + 20% dirty rows (10) = 60 total ---\n",
    "\n",
    "# Start fresh (optional)\n",
    "cur.execute(\"TRUNCATE TABLE departments RESTART IDENTITY CASCADE;\")\n",
    "conn.commit()\n",
    "\n",
    "base_locations = [\"Toronto\", \"Vancouver\", \"Montreal\", \"Calgary\", \"Ottawa\", \"Edmonton\", \"Winnipeg\", \"Halifax\"]\n",
    "dept_rows = []\n",
    "\n",
    "# 50 clean departments\n",
    "for i in range(1, 51):\n",
    "    dept_name = f\"Department_{i:02d}\"\n",
    "    location = random.choice(base_locations)\n",
    "    dept_rows.append((dept_name, location))\n",
    "\n",
    "# 10 dirty departments (20% of 50)\n",
    "dirty_depts = [\n",
    "    (None, \"Toronto\"),                    # missing name\n",
    "    (\"   \", \"Vancouver\"),                 # blank name\n",
    "    (\"Department_01\", \"Montreal\"),        # duplicate name\n",
    "    (\"Department_02\", None),              # missing location\n",
    "    (\"Department_03\", \"   \"),             # blank location\n",
    "    (\"Dept_üí•_04\", \"Calgary\"),            # weird chars\n",
    "    (\"Department_51\", \"12345\"),           # non-location\n",
    "    (\"Department_52\", \"Toronto \"),        # trailing space\n",
    "    (\"department_53\", \"toronto\"),         # inconsistent casing\n",
    "    (\"Department_54\", \"N/A\")              # placeholder value\n",
    "]\n",
    "dept_rows.extend(dirty_depts)\n",
    "\n",
    "cur.executemany(\n",
    "    \"INSERT INTO departments (department_name, location) VALUES (%s, %s);\",\n",
    "    dept_rows\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "print(\"‚úÖ Inserted departments:\", len(dept_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Add department_id to employees and assign departments (1..50) ---\n",
    "cur.execute(\"ALTER TABLE employees ADD COLUMN IF NOT EXISTS department_id INTEGER;\")\n",
    "\n",
    "# Assign ONLY valid clean departments 1..50 to the existing employees\n",
    "cur.execute(\"UPDATE employees SET department_id = floor(random() * 50 + 1) WHERE department_id IS NULL;\")\n",
    "conn.commit()\n",
    "\n",
    "# --- Add 20% dirty employees (10) on top of the existing 50 = 60 total ---\n",
    "# NOTE: employee_id is SERIAL PK, so we keep PK valid and make other columns dirty.\n",
    "\n",
    "dirty_positions = [\"\", None, \"Data Scientist\", \"???\", \"Software Engineer\"]\n",
    "dirty_employees = []\n",
    "for _ in range(10):\n",
    "    dirty_employees.append((\n",
    "        random.choice([None, \"   \", fake.name(), fake.name()]),     # name dirty\n",
    "        random.choice(dirty_positions),                             # position dirty\n",
    "        random.choice([None, fake.date_between(start_date='-5y', end_date='today'),\n",
    "                       fake.date_between(start_date='today', end_date='+2y')]),  # start_date null/future\n",
    "        random.choice([None, -5000, 0, 10_000_000, random.randint(30000, 150000)]),  # salary null/negative/outlier\n",
    "        random.choice([None, 1, 2, 3, 4, 999, random.randint(1, 50)])  # dept null/invalid (999)\n",
    "    ))\n",
    "\n",
    "cur.executemany(\n",
    "    \"INSERT INTO employees (name, position, start_date, salary, department_id) VALUES (%s, %s, %s, %s, %s);\",\n",
    "    dirty_employees\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "print(\"‚úÖ Added dirty employees:\", len(dirty_employees))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"\"\"\n",
    "SELECT e.*, d.department_name\n",
    "FROM employees e\n",
    "JOIN departments d\n",
    "ON e.department_id = d.department_id;\n",
    "\"\"\"\n",
    "df_joined = pd.read_sql(query, conn)\n",
    "df_joined.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Project Table (with FKs) + Dirty Data\n",
    "We create a `projects` table where `project_id` is the primary key and `employee_id`, `department_id` are foreign keys.\n",
    "We insert **50 clean** projects + **10 dirty** projects (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS projects (\n",
    "    project_id SERIAL PRIMARY KEY,\n",
    "    project_name VARCHAR(100),\n",
    "    project_description TEXT,\n",
    "    start_date DATE,\n",
    "    end_date DATE,\n",
    "    budget INTEGER,\n",
    "    employee_id INTEGER REFERENCES employees(employee_id),\n",
    "    department_id INTEGER REFERENCES departments(department_id)\n",
    ");\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "# Start fresh (optional)\n",
    "cur.execute(\"TRUNCATE TABLE projects RESTART IDENTITY CASCADE;\")\n",
    "conn.commit()\n",
    "\n",
    "print(\"‚úÖ projects table ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Insert 50 clean projects ---\n",
    "clean_projects = []\n",
    "for i in range(1, 51):\n",
    "    p_name = f\"Project_{i:02d}\"\n",
    "    p_desc = fake.sentence(nb_words=12)\n",
    "    s_date = fake.date_between(start_date='-2y', end_date='-30d')\n",
    "    e_date = fake.date_between(start_date='-29d', end_date='+180d')\n",
    "    if e_date < s_date:\n",
    "        s_date, e_date = e_date, s_date\n",
    "    budget = random.randint(50_000, 2_000_000)\n",
    "\n",
    "    # Use valid FKs from clean ranges\n",
    "    employee_id = random.randint(1, 50)      # first 50 are \"clean\" employees\n",
    "    department_id = random.randint(1, 50)    # first 50 are \"clean\" departments\n",
    "\n",
    "    clean_projects.append((p_name, p_desc, s_date, e_date, budget, employee_id, department_id))\n",
    "\n",
    "# --- Insert 10 dirty projects (20% of 50) ---\n",
    "dirty_projects = [\n",
    "    (None, fake.sentence(), None, None, None, random.randint(1, 60), random.randint(1, 60)),    # missing values\n",
    "    (\"   \", \"\", fake.date_between('-1y','today'), fake.date_between('-1y','today'), -1000, random.randint(1, 60), random.randint(1, 60)),  # blank + negative budget\n",
    "    (\"Project_01\", fake.text(max_nb_chars=50), fake.date_between('-1y','today'), fake.date_between('-2y','-1y'), 50000, random.randint(1, 60), random.randint(1, 60)),  # end before start\n",
    "    (\"Proj_üí•_X\", None, fake.date_between('-6mo','today'), fake.date_between('today','+6mo'), 999999999, random.randint(1, 60), random.randint(1, 60)),  # outlier budget\n",
    "    (\"Project_51\", fake.sentence(), fake.date_between('-1y','today'), fake.date_between('today','+1y'), 0, None, random.randint(1, 60)),   # employee_id null\n",
    "    (\"Project_52\", fake.sentence(), fake.date_between('-1y','today'), fake.date_between('today','+1y'), 100000, random.randint(1, 60), None), # department_id null\n",
    "    (\"Project_53\", fake.sentence(), fake.date_between('-1y','today'), fake.date_between('today','+1y'), 100000, 60, random.randint(51, 60)), # uses dirty employee/dept but valid FK\n",
    "    (\"Project_54\", fake.sentence(), fake.date_between('-1y','today'), fake.date_between('today','+1y'), 100000, random.randint(51, 60), 60), # uses dirty dept but valid FK\n",
    "    (\"Project_55\", fake.sentence(), fake.date_between('-1y','today'), fake.date_between('today','+1y'), None, random.randint(1, 60), random.randint(1, 60)), # missing budget\n",
    "    (\"Project_56\", fake.sentence(), fake.date_between('-1y','today'), fake.date_between('today','+1y'), -999999, random.randint(1, 60), random.randint(1, 60)), # negative budget\n",
    "]\n",
    "\n",
    "# Insert clean first\n",
    "cur.executemany(\n",
    "    \"INSERT INTO projects (project_name, project_description, start_date, end_date, budget, employee_id, department_id) VALUES (%s,%s,%s,%s,%s,%s,%s);\",\n",
    "    clean_projects\n",
    ")\n",
    "conn.commit()\n",
    "print(\"‚úÖ Inserted clean projects:\", len(clean_projects))\n",
    "\n",
    "# Insert dirty rows, but some have invalid FKs -> catch and insert the ones that pass\n",
    "inserted_dirty = 0\n",
    "for row in dirty_projects:\n",
    "    try:\n",
    "        cur.execute(\n",
    "            \"INSERT INTO projects (project_name, project_description, start_date, end_date, budget, employee_id, department_id) VALUES (%s,%s,%s,%s,%s,%s,%s);\",\n",
    "            row\n",
    "        )\n",
    "        conn.commit()\n",
    "        inserted_dirty += 1\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        print(\"‚ö†Ô∏è Dirty project insert failed (expected for FK violation):\", row[0], \"| Error:\", str(e)[:120], \"...\")\n",
    "print(\"‚úÖ Inserted dirty projects (that passed constraints):\", inserted_dirty)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. EDA on Dirty Data (Employees, Departments, Projects)\n",
    "We pull the three tables into pandas and quickly inspect missing values, duplicates, outliers, and logical issues (like `end_date < start_date`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_emp = pd.read_sql(\"SELECT * FROM employees;\", conn)\n",
    "df_dept = pd.read_sql(\"SELECT * FROM departments;\", conn)\n",
    "df_proj = pd.read_sql(\"SELECT * FROM projects;\", conn)\n",
    "\n",
    "display(df_emp.head())\n",
    "display(df_dept.head())\n",
    "display(df_proj.head())\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"employees:\", df_emp.shape)\n",
    "print(\"departments:\", df_dept.shape)\n",
    "print(\"projects:\", df_proj.shape)\n",
    "\n",
    "def eda_quick(df, name):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(name)\n",
    "    print(\"=\"*60)\n",
    "    print(df.info())\n",
    "    print(\"\\nMissing values:\")\n",
    "    print(df.isna().sum().sort_values(ascending=False).head(15))\n",
    "    print(\"\\nFull-row duplicates:\", df.duplicated().sum())\n",
    "    print(\"\\nDescribe (numeric):\")\n",
    "    display(df.describe(include=[np.number]).T)\n",
    "\n",
    "eda_quick(df_emp, \"EMPLOYEES\")\n",
    "eda_quick(df_dept, \"DEPARTMENTS\")\n",
    "eda_quick(df_proj, \"PROJECTS\")\n",
    "\n",
    "# Specific \"dirty\" checks\n",
    "print(\"\\nEmployees with invalid department_id (not in departments):\")\n",
    "invalid_emp_dept = df_emp.loc[~df_emp['department_id'].isin(df_dept['department_id']) & df_emp['department_id'].notna(), ['employee_id','name','department_id']]\n",
    "display(invalid_emp_dept.head(20))\n",
    "\n",
    "print(\"\\nProjects with negative/zero budget:\")\n",
    "display(df_proj.loc[df_proj['budget'].fillna(0) <= 0, ['project_id','project_name','budget']].head(20))\n",
    "\n",
    "print(\"\\nProjects where end_date < start_date:\")\n",
    "bad_dates = df_proj.dropna(subset=['start_date','end_date']).loc[df_proj['end_date'] < df_proj['start_date']]\n",
    "display(bad_dates[['project_id','project_name','start_date','end_date']].head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Merge the 3 Tables (Show Relationships)\n",
    "We merge:\n",
    "1) `employees` ‚Üî `departments` using `department_id`\n",
    "2) `projects` ‚Üî `employees` using `employee_id`\n",
    "3) `projects` ‚Üî `departments` using `department_id`\n",
    "\n",
    "This demonstrates the PK/FK connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# employees + departments\n",
    "df_emp_dept = df_emp.merge(df_dept, on='department_id', how='left', suffixes=('', '_dept'))\n",
    "\n",
    "# projects + employees\n",
    "df_proj_emp = df_proj.merge(df_emp, on='employee_id', how='left', suffixes=('', '_emp'))\n",
    "\n",
    "# full merge: projects + employees + departments\n",
    "df_all = df_proj_emp.merge(df_dept, on='department_id', how='left', suffixes=('', '_dept'))\n",
    "\n",
    "print(\"Merged shape:\", df_all.shape)\n",
    "display(df_all.head(10))\n",
    "\n",
    "# Simple \"connection\" checks\n",
    "print(\"\\nProjects missing employee match:\", df_all['name'].isna().sum())\n",
    "print(\"Projects missing department match:\", df_all['department_name'].isna().sum())\n",
    "\n",
    "# Example aggregation: avg budget by department (ignoring missing budgets)\n",
    "budget_by_dept = df_all.groupby('department_name', dropna=False)['budget'].mean().sort_values(ascending=False)\n",
    "display(budget_by_dept.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf02dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "pivot = df_joined.pivot_table(values='salary', index='department_name', columns='position', aggfunc='mean')\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.heatmap(pivot, annot=True, fmt=\".0f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Average Salary by Department and Position\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce47bb",
   "metadata": {},
   "source": [
    "## 7. Conclusions\n",
    "This notebook demonstrates a complete data engineering and EDA workflow."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
